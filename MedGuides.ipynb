{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MedGuides.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNCTWWESur5KzmR+izw6rZP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"lkyJAxC62aUc"},"source":["%xmode Verbose"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcTIGpPkSVN6"},"source":["## install stuff\n","import subprocess\n","command = [\"pip3\", \"install\", \"urllib\"]\n","a = [\"PyPDF2\", \"bs4\"]\n","for i in a:\n","  command.append(i)\n","  subprocess.run(command, capture_output=True)\n","  command = [\"pip3\", \"install\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kN98MdSMSMLT"},"source":["import PyPDF2\n","import requests \n","import re\n","from bs4 import BeautifulSoup\n","import os\n","import urllib.request\n","from PyPDF2 import PdfFileWriter, PdfFileReader\n","import datetime\n","\n","\n","# scraping using regular expression \n","url1 = \"https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm?event=medguide.page\"\n","page1 = requests.get(url1)\n","soup1 = BeautifulSoup(page1.content, 'html.parser')\n","urlregex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n","urls = re.findall(urlregex,soup1.prettify())     \n","lst = []\n","for i in urls:\n","  if len(i)>0:\n","    if str(i).find(\"pdf\")!=-1:\n","      for j in i:\n","        if len(j) > 0:\n","          lst.append(j)\n","\n","lst = lst[2:]\n","\n","\n","#!wget https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UjrsAUWMZEFK"},"source":["#delete files\n","\n","\n","import subprocess\n","for i in os.listdir():\n","  if str(i).find(\"pdf\") != -1:\n","     subprocess.run([\"rm\", str(i)])\n","\n","\n","\n","\n","def handle_a_link(name, link):\n","  if str(link).find(\"page\") !=-1:\n","    regex= r\"page=\\d+\"\n","    num = re.findall(regex , str(link))[0]\n","    num = re.findall(\"\\d+\" , num)[0]\n","    try:\n","      urllib.request.urlretrieve(link, \"temp.pdf\" )\n","      inputpdf = PdfFileReader(open(\"temp.pdf\", \"rb\"))\n","      if int(num) > inputpdf.pages.lengthFunction():\n","         print(\"FDA mistake detected\", link)\n","      else:\n","        myrange = (num, inputpdf.pages.lengthFunction())\n","        output = PdfFileWriter()\n","        for i in range(int(myrange[0])-1,int(myrange[1])):\n","            output.addPage(inputpdf.getPage(i))\n","        medguidename = name\n","        with open(\"%s.pdf\" % medguidename, \"wb\") as outputStream:\n","          output.write(outputStream)\n","    except:\n","      pass\n","  else:\n","      medguidename = name\n","      try:\n","        urllib.request.urlretrieve(link, \"%s.pdf\" % medguidename)\n","      except:\n","        pass\n","\n","\n","import PyPDF2\n","import requests \n","import re\n","from bs4 import BeautifulSoup\n","\n","url1 = \"https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm?event=medguide.page\"\n","\n","page1 = requests.get(url1)\n","soup1 = BeautifulSoup(page1.content, 'html.parser')\n","\n","\n","\n","\n","tab = soup1.find_all(\"td\")\n","len(tab)\n","block= len(tab)/7\n","dicto= {}\n","\n","#for i in range(100):\n","for i in range(int(block)):\n","  currentplace = i*7\n","\n","  drug_name = 0 + currentplace\n","  active = 1 + currentplace\n","  form = 2 + currentplace\n","  Company = 4 + currentplace\n","  link = 6 + currentplace\n","\n","  drug_name = tab[drug_name].text[1:]\n","  drug_name = re.match(\"\\S+\", drug_name).group()\n","  active = tab[active].text\n","  active = re.match(\"\\S+\", active).group()\n","  form = tab[form].text\n","  #form = re.match(\"\\S+\", form).group()\n","  Company = tab[Company].text\n","  Company = re.match(\"\\S+\", Company).group()\n","  link = tab[link].text\n","  link = re.match(\"\\S+\", link).group()\n","  medguidename = str(drug_name) +\" \"+ str(active) +\" \"+ str(form)+\" \"+str(Company) + \" MedGuide\"\n","  medguidename = medguidename.replace(\"/\", \" \")\n","  dicto[medguidename] = link\n","\n","print(datetime.datetime.now())\n","for name, link in dicto.items():\n","  handle_a_link(name, link)\n","print(datetime.datetime.now())\n","\n","\n","for i in os.listdir():\n","  if str(i).find(\"pdf\") != -1:\n","    subprocess.run([\"mv\", str(i), \"mydir/\" +str(i) ])\n","\n","subprocess.run([\"rm\", \"mydir/temp.pdf\"])\n","subprocess.run([\"zip\", \"-r\",\"MedGuides.zip\", \"mydir\"])\n","files.download(\"MedGuides.zip\")\n"],"execution_count":null,"outputs":[]}]}